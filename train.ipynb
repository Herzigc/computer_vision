{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base model\n",
    "\n",
    "Our base model is a plain ResNet50 model which is initialized with random weights and therefore has no prior knowledge of any images."
   ],
   "id": "dcd6f66529731f84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:51:24.208462Z",
     "start_time": "2025-04-08T13:51:20.081375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import preprocessing, layers, Sequential\n",
    "from keras.applications import ResNet50\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.resnet50 import preprocess_input"
   ],
   "id": "d8d36dc4e6275779",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lodu\\anaconda3\\envs\\dev\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:51:31.183579Z",
     "start_time": "2025-04-08T13:51:31.180192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)"
   ],
   "id": "f75d5c257d844fbb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:52:50.767862Z",
     "start_time": "2025-04-08T13:52:50.505761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data_dir = './data_split/train'\n",
    "test_data_dir = './data_split/test'\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_images = preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_images = preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_images.class_names\n",
    "\n",
    "train_ds = train_images.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_ds = val_images.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "160fd4702f36cdcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1545 files belonging to 3 classes.\n",
      "Found 517 files belonging to 3 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build model from scratch (random init)\n",
    "base_model = ResNet50(include_top=True, weights=None, input_shape=(224, 224, 3), classes=len(class_names)) # include_top=True adds the classification layer\n",
    "\n",
    "base_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "id": "ff28c547dc0c01ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = base_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ],
   "id": "8ebd1a885582f984",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history['loss'], label='loss')\n",
    "    plt.plot(history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history.history)"
   ],
   "id": "9a87b7fdff3f8688",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.plot(history['accuracy'], label='accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy(history.history)"
   ],
   "id": "b3c55c21256a3ec9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_loss, test_accuracy = base_model.evaluate(val_ds)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "print(f'Test loss: {test_loss}')"
   ],
   "id": "87db6502c6cf3214"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transfer learning",
   "id": "390ce73d9d44ba89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "649d67db103bacf9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data augmentation",
   "id": "c631b25da9f424fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:53:17.249820Z",
     "start_time": "2025-04-08T13:53:17.187318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zoom_aug = Sequential([\n",
    "    layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "random_zoom_train = train_images.map(lambda x, y: (preprocess_input(zoom_aug(x)), y))\n",
    "\n",
    "\n"
   ],
   "id": "585bf41a3e404120",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:53:18.515936Z",
     "start_time": "2025-04-08T13:53:18.297708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "crop_aug = Sequential([\n",
    "    layers.RandomCrop(224, 224),\n",
    "])\n",
    "\n",
    "increased_size_train = preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "random_crop_train = increased_size_train.map(lambda x, y: (preprocess_input(crop_aug(x)), y))\n",
    "\n",
    "\n"
   ],
   "id": "bfa23be6b75b7402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1545 files belonging to 3 classes.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:53:59.326435Z",
     "start_time": "2025-04-08T13:53:59.267805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translate_aug = Sequential([\n",
    "    layers.RandomTranslation(0.2, 0.2),\n",
    "])\n",
    "\n",
    "random_translate_train = train_images.map(lambda x, y: (preprocess_input(translate_aug(x)), y))\n",
    "\n",
    "\n"
   ],
   "id": "9bec8d7a05d1887e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Different architectures",
   "id": "5db42f38b1bf1d73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "742429091d5a2828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test on online images",
   "id": "a6465cc284b5c2a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e6138846c42eca5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Conclusion",
   "id": "1de24c423ab4b0e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
